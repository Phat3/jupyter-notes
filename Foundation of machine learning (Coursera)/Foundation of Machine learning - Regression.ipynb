{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center; color:red'>Foundation of Machine learning</h1>\n",
    "\n",
    "\n",
    "<p style='text-align:center'>**ALL THE IMAGES ARE CREATED AND BELONG TO THE COURSE <a href='https://www.coursera.org/learn/ml-foundations'> Machine Learning Foundations: A Case Study Approach</a> MADE BY University of Washington**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Foundation-of-Machine-learning\">Foundation of Machine learning</a></div><div class=\"lev1\"><a href=\"#Regeression\">Regeression</a></div><div class=\"lev2\"><a href=\"#Use-case---Predicting-the-value-of-a-house\">Use case - Predicting the value of a house</a></div><div class=\"lev2\"><a href=\"#Naive-approach\">Naive approach</a></div><div class=\"lev2\"><a href=\"#Linear-regression\">Linear regression</a></div><div class=\"lev2\"><a href=\"#Residual-sum-of-squares-(RSS)\">Residual sum of squares (RSS)</a></div><div class=\"lev3\"><a href=\"#Retrieving-the-best-price\">Retrieving the best price</a></div><div class=\"lev3\"><a href=\"#Problems\">Problems</a></div><div class=\"lev2\"><a href=\"#High-order-regression\">High order regression</a></div><div class=\"lev2\"><a href=\"#How-can-we-choose-the-proper-model?\">How can we choose the proper model?</a></div><div class=\"lev3\"><a href=\"#Training-/-Test-curves\">Training / Test curves</a></div><div class=\"lev3\"><a href=\"#Adding-other-features\">Adding other features</a></div><div class=\"lev2\"><a href=\"#Regression-pipeline-summary\">Regression pipeline summary</a></div><div class=\"lev1\"><a href=\"#Classification\">Classification</a></div><div class=\"lev2\"><a href=\"#Use-case---Intelligent-restaurant-classifier\">Use case - Intelligent restaurant classifier</a></div><div class=\"lev2\"><a href=\"#Linear-classifier\">Linear classifier</a></div><div class=\"lev3\"><a href=\"#Problems\">Problems</a></div><div class=\"lev2\"><a href=\"#Decision-boundaries\">Decision boundaries</a></div><div class=\"lev2\"><a href=\"#Training-a-classifier-(learning-the-weights)\">Training a classifier (learning the weights)</a></div><div class=\"lev3\"><a href=\"#Test-the-evaluation-of-the-weights\">Test the evaluation of the weights</a></div><div class=\"lev3\"><a href=\"#What-is-a-good-accuracy?\">What is a good accuracy?</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regeression\n",
    "\n",
    "**REGRESSION** : We have a set of features and we wanna model how this feature change when the values of the feature changes.\n",
    "\n",
    "We can also use regression for **classification** (heavily used in the SPAM filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case - Predicting the value of a house\n",
    "\n",
    "In regression we refer to the axis as:\n",
    "- **x variable** --> **feature, covariate or predictor**\n",
    "- **y variable** --> **observation or response**\n",
    "\n",
    "## Naive approach\n",
    "1. Consider the aspects of your house\n",
    "2. Look at other recent sales that have occurred in my neighborhood.\n",
    "3. Plot a graph of the sales price(y-axis) and the square feet(x-axys) of the houses sold recently in my neighborhood.\n",
    "4. Look at how big my house is and look for other sales of houses of roughly the same size of mine (In a certain range).\n",
    "5. I can't end up having a few valid data and discard all the other information coming from other data not inside my range.\n",
    "\n",
    "**NOT CORRECT!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "We can build a model the relationship between the square footage of the house and the house sales price using **linear regression**.\n",
    "\n",
    "The model is notingh more than a line having the following equation:\n",
    "\n",
    "<p style='text-align:center'>**fW(x) = W0 + W1*x**</p>\n",
    "<p style='text-align:center'>**W = (W0, W1)**</p>\n",
    "\n",
    "<img src=\"CM71THH7NOKQPHKUU4GR6D7IPBE2L3MG.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **W0** = intercept \n",
    "- **W1** = slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find out the **best possible values** for **W0** and **W1**!!\n",
    "\n",
    "We have to define a cost for a given line using **residual sum of squares (RSS)**\n",
    "\n",
    "## Residual sum of squares (RSS)\n",
    "We take the candidate line and for each observation we look how far is that observation from our line. This will give us the **distance between the real value (the observation) and the value we predict (the point on the line)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"B0DXKTKXN6MAU5L162UY5T99RJ0LGWPT.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance is squared and RSS is calculated following this formula:\n",
    "<p style='text-align:center'>**RSS(W0, W1) = ( price(house1) - (W0 + W1*square_feet(house1) )^2 + ... + ( price(houseN) - (W0 + W1*square_feet(houseN) )^2**</p>\n",
    "\n",
    "The best candidate **Wcan = (W0can, W1can)** is the one which **MINIMIZE** the RSS value. This value will be the best candidate because the line produced with this parameters has, overall, the observations closest to the predictions made, so the predictions tend to be good.\n",
    "\n",
    "### Retrieving the best price\n",
    "it is sufficient to substitute the predictor (my house square feet) in the retrived model in order to find the best possible response (sale price).\n",
    "<p style='text-align:center'>**best_price = W0can + W1can*square_feet(myHouse)**</p>\n",
    "\n",
    "### Problems\n",
    "\n",
    "Are we sure that the best model for our problem is linear? It could also be **quadratic** or more.\n",
    "\n",
    "## High order regression\n",
    "It is a sub-type of linear regression (actually everybody refers to it as linear regression).\n",
    "\n",
    "If we take into account the quadratic regression the model is no more an equation that defines a straight line but it is a **parabola**:\n",
    "<p style='text-align:center'>**fW(x) = W0 + W1*x + W2*x^2**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"VUOF44KIMPF68XS35D6DD8F5JD40WTTQ.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same formula of the RSS calculation, substituting the parabola equation in the distance calculus, we can verify if this model is better or worse than the linear one.\n",
    "\n",
    "We can increase the order of the function used to build the model but it can produce wrong results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"HXTXUDL8V42ELFJYSRKCDLXVJUBDO8OI.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the RSS value is the minimum possible one **BUT** the model is wrong: the value of my house predicted by this model is **TOO LOW**!!\n",
    "\n",
    "This problem is called <span style='color:red'>OVERFITTING</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we choose the proper model?\n",
    "The key idea is that we want to simulate predictions on observations that we already have.\n",
    "\n",
    "First of all, we have to split our dataset into two categories;\n",
    "- **Training set** : Data used to fit our model (blue dots).\n",
    "- **Test set** : Data use in order to validate our predictions (gray dots).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"I6H3C7RFDXDTCB0R87TMLI2AGYI68J2G.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to calculate the **training error** thai is the RSS **only** of the data in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"Y6QHFXXLWJOC5WX9VEQOBT7DDLL74P20.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same calculus in order to retrieve the **test error** (The RSS calculated only on the data included in the test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"XWMIWSBX54TSNG1PXU4V0K9BE14QEJYJ.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training / Test curves\n",
    "As we saw before, the higher the polynomial that builds our model is the lower will be our training error (the RSS calculated only on the training set). This happens because the line can touch perfectly every single data of our model, but this is not an indication of correctness (Remember the **OVERFITTING** problem!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"FNJUXODVTK27HJL2FMST6O19LS9QY4XK.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the test error things are different: the error decrease until a certain model complexity but after that point the error will increase, detecting the overfitting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"PRHGV4QP8RNX6SW8UL1O4CIENH0ISPY3.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding other features\n",
    "In this example, the square feet feature of the house is not sufficient in order to make a good prediction. We can have an house that has the same square feet as ours but only one bathroom instead of three.\n",
    "\n",
    "We can add other feature increasing the dimensions of our graph (for example adding the number of bathrooms on the z-axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"QPQODESA9FKX5GV0LJ3V8E5696PS9SRS.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our model won't be a line anymore but a **plane** identified by this equation:\n",
    "<p style='text-align:center'>**fW(x) = W0 + W1*square_feet + W2*#bathrooms**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"I6NL8B94HEM5L5Q4LJKMRS740Q82JIVO.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression pipeline summary\n",
    "We can summarize the whole process of regression described so far with this picture: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"N0I182O9KRI64CLGFC7JM704SBSGXLLN.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start from a training data we a lot of features.\n",
    "2. With the feature extraction component select only the important features.\n",
    "3. With a machine learning model, regression in this case, predict the values we want.\n",
    "4. Validate the predictions with the test set in the quality metric component.\n",
    "5. With a machine learning algorithm adjust the parameters of the model with respect to the results of the quality metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "##Â Use case - Intelligent restaurant classifier\n",
    "\n",
    "1. Get all the reviews about one restaurant\n",
    "2. Break all reviews into sentence\n",
    "3. Select only the sentences regarding the topic in which we are interested (sushi for example)\n",
    "4. Pass these sentences as input into a **sentence sentiment classifier** in order to extract if a sentence is positive or negative.\n",
    "5. Create the prediction about the quality of the topic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear classifier\n",
    "\n",
    "A simple linear classifier takes as input:\n",
    "* The sentence that has to be classified\n",
    "* A list of words with their weights (positive words weight > 0; negative words weight < 0)\n",
    "\n",
    "The classifier then sums up the weight of each word inside the sentence and it classify the sentence as follow:\n",
    "* **result > 0 --> positive sentence**\n",
    "* **result < 0 --> negative sentence**\n",
    "\n",
    "This type of classifier is called **linear** because **outputs is weighted sum of inputs**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"XFYYSPNO0W9QWH5MY6CBPT3V8I1407L4.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems\n",
    "\n",
    "* How do we get the list of positive and negative words?\n",
    "\n",
    "\n",
    "* Words have different degree of sentiment (**awesome** is more positive than **good**)\n",
    "\n",
    "These two problems are addressed by **learning classifier**\n",
    "\n",
    "* Single words are not enough (**good** is positive but **not good** is negative)\n",
    "\n",
    "This problem instead is addressed by **elaborate features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision boundaries\n",
    "We need to find a threshold that differentiate the positive sentence from the negative ones.\n",
    "\n",
    "This threshold is called **decision boundary**\n",
    "\n",
    "If we consider only two words, awful and awesome for example, weighed respectively -1.5 and 1.0 the decision boundary is retrieved in this way:\n",
    "\n",
    "<p style='text-align:center'>**1.0#awesome -1.5#awful = 0**</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"HLCK21LOA6YWXJG902ECUOE4PK3W2LBR.png\"/>\n",
    "\n",
    "In this case the decision boundary is represented by a line (we have only two words so only two dimensions).\n",
    "If we have had:\n",
    "\n",
    "* 3 words --> plane\n",
    "\n",
    "* more than 3 words --> hyperplane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier (learning the weights)\n",
    "In order to train a classifier we have to:\n",
    "1. Get a data set of sentences already marked as positive or negative\n",
    "2. Split the dataset into a training set and a test set\n",
    "3. feed the training set as input to the **learn classifier** (this learn classifier is gonna learn the appropriate weights for the words)\n",
    "4. The weights learned by the learn classifier are used to score every element in the test set and evaluate how good is our learn classifier \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"UR5IRR9MPVS4MOHS37UJDYQYG21EKS55.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the evaluation of the weights\n",
    "In order to test the goodness of the retrieved weights we need to:\n",
    "1. Feed a number of sentence, already known to be positive or negative, to our classifier \n",
    "2. Get the prediction made by our classifier\n",
    "3. Compare the prediction with the real sentiment of the sentence\n",
    "4. If the prediction match the real sentiment than correct++ otherwise mistakes++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"BKP2NX0BEFL537QSDB853NE55TXB48OC.png\"/>\n",
    "\n",
    "The **error rate of the classifier** is then calculated as:\n",
    "<p style='text-align:center'>**classifier_error = #mistakes / #sentences**</p>\n",
    "\n",
    "while the **accuracy of the classifier** is retrieved as:\n",
    "<p style='text-align:center'>**classifier_accuracy = #correct / #sentences**</p>\n",
    "\n",
    "obviously the error and the accuracy are bound together:\n",
    "<p style='text-align:center'>**classifier_error = 1 - classifier_accuracy**</p>\n",
    "\n",
    "### What is a good accuracy?\n",
    "At **least** our accuracy must be better than the random guesses on data (for example if i have only two classes of decision like positive and negative, my accuracy must be > 50%).\n",
    "\n",
    "Given that an high accuracy rate isn't always a good indicator of the quality of our classifier. For example if we consider the SPAM email example the data shows that 90% of the emails sent are SPAM; if we have a classifier with a 90% accuracy predicting every email sent is SPAM gives us a 90% of accuracy but actually **our classifier always make the SAME prediction for every email!!!**.\n",
    "\n",
    "This problem is called <span style='color:red'>MAJORITY CLASS PREDICTION</span>.\n",
    "\n",
    "This problem causes the **impression that our classifier has amazing performance when there is class imbalance (one class is more common than others)** even if it was poorly designed.\n",
    "\n",
    "\n",
    "So how can we design a good classifier? we have to ask ourself the following questions:\n",
    "* Is there class imbalance?\n",
    "\n",
    "\n",
    "* How does it compare to random guessing?\n",
    "\n",
    "\n",
    "* What accuracy does my application need?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": false,
   "toc_section_display": "none",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "height": "546px",
   "left": "965.125px",
   "right": "20px",
   "top": "119px",
   "width": "292px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
