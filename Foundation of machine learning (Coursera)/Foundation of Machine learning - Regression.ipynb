{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center; color:red'>Foundation of Machine learning</h1>\n",
    "\n",
    "\n",
    "<p style='text-align:center'>**ALL THE IMAGES ARE CREATED AND BELONG TO THE COURSE <a href='https://www.coursera.org/learn/ml-foundations'> Machine Learning Foundations: A Case Study Approach</a> MADE BY University of Washington**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Foundation-of-Machine-learning\">Foundation of Machine learning</a></div><div class=\"lev1\"><a href=\"#Regeression\">Regeression</a></div><div class=\"lev2\"><a href=\"#Use-case---Predicting-the-value-of-a-house\">Use case - Predicting the value of a house</a></div><div class=\"lev2\"><a href=\"#Naive-approach\">Naive approach</a></div><div class=\"lev2\"><a href=\"#Linear-regression\">Linear regression</a></div><div class=\"lev2\"><a href=\"#Residual-sum-of-squares-(RSS)\">Residual sum of squares (RSS)</a></div><div class=\"lev3\"><a href=\"#Retrieving-the-best-price\">Retrieving the best price</a></div><div class=\"lev3\"><a href=\"#Problems\">Problems</a></div><div class=\"lev2\"><a href=\"#High-order-regression\">High order regression</a></div><div class=\"lev2\"><a href=\"#How-can-we-choose-the-proper-model?\">How can we choose the proper model?</a></div><div class=\"lev3\"><a href=\"#Training-/-Test-curves\">Training / Test curves</a></div><div class=\"lev3\"><a href=\"#Adding-other-features\">Adding other features</a></div><div class=\"lev2\"><a href=\"#Regression-pipeline-summary\">Regression pipeline summary</a></div><div class=\"lev1\"><a href=\"#Classification\">Classification</a></div><div class=\"lev2\"><a href=\"#Use-case---Intelligent-restaurant-classifier\">Use case - Intelligent restaurant classifier</a></div><div class=\"lev2\"><a href=\"#Linear-classifier\">Linear classifier</a></div><div class=\"lev3\"><a href=\"#Problems\">Problems</a></div><div class=\"lev2\"><a href=\"#Decision-boundaries\">Decision boundaries</a></div><div class=\"lev2\"><a href=\"#Training-a-classifier-(learning-the-weights)\">Training a classifier (learning the weights)</a></div><div class=\"lev3\"><a href=\"#Test-the-evaluation-of-the-weights\">Test the evaluation of the weights</a></div><div class=\"lev3\"><a href=\"#What-is-a-good-accuracy?\">What is a good accuracy?</a></div><div class=\"lev3\"><a href=\"#Types-of-errors\">Types of errors</a></div><div class=\"lev2\"><a href=\"#Learning-curves\">Learning curves</a></div><div class=\"lev2\"><a href=\"#Level-of-confidence\">Level of confidence</a></div><div class=\"lev2\"><a href=\"#Classification-pipeline-summary\">Classification pipeline summary</a></div><div class=\"lev1\"><a href=\"#Clustering-and-similarity\">Clustering and similarity</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regeression\n",
    "\n",
    "**REGRESSION** : We have a set of features and we wanna model how this feature change when the values of the feature changes.\n",
    "\n",
    "We can also use regression for **classification** (heavily used in the SPAM filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case - Predicting the value of a house\n",
    "\n",
    "In regression we refer to the axis as:\n",
    "- **x variable** --> **feature, covariate or predictor**\n",
    "- **y variable** --> **observation or response**\n",
    "\n",
    "## Naive approach\n",
    "1. Consider the aspects of your house\n",
    "2. Look at other recent sales that have occurred in my neighborhood.\n",
    "3. Plot a graph of the sales price(y-axis) and the square feet(x-axys) of the houses sold recently in my neighborhood.\n",
    "4. Look at how big my house is and look for other sales of houses of roughly the same size of mine (In a certain range).\n",
    "5. I can't end up having a few valid data and discard all the other information coming from other data not inside my range.\n",
    "\n",
    "**NOT CORRECT!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "We can build a model the relationship between the square footage of the house and the house sales price using **linear regression**.\n",
    "\n",
    "The model is notingh more than a line having the following equation:\n",
    "\n",
    "<p style='text-align:center'>**fW(x) = W0 + W1*x**</p>\n",
    "<p style='text-align:center'>**W = (W0, W1)**</p>\n",
    "\n",
    "<img src=\"CM71THH7NOKQPHKUU4GR6D7IPBE2L3MG.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **W0** = intercept \n",
    "- **W1** = slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find out the **best possible values** for **W0** and **W1**!!\n",
    "\n",
    "We have to define a cost for a given line using **residual sum of squares (RSS)**\n",
    "\n",
    "## Residual sum of squares (RSS)\n",
    "We take the candidate line and for each observation we look how far is that observation from our line. This will give us the **distance between the real value (the observation) and the value we predict (the point on the line)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"B0DXKTKXN6MAU5L162UY5T99RJ0LGWPT.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance is squared and RSS is calculated following this formula:\n",
    "<p style='text-align:center'>**RSS(W0, W1) = ( price(house1) - (W0 + W1*square_feet(house1) )^2 + ... + ( price(houseN) - (W0 + W1*square_feet(houseN) )^2**</p>\n",
    "\n",
    "The best candidate **Wcan = (W0can, W1can)** is the one which **MINIMIZE** the RSS value. This value will be the best candidate because the line produced with this parameters has, overall, the observations closest to the predictions made, so the predictions tend to be good.\n",
    "\n",
    "### Retrieving the best price\n",
    "it is sufficient to substitute the predictor (my house square feet) in the retrived model in order to find the best possible response (sale price).\n",
    "<p style='text-align:center'>**best_price = W0can + W1can*square_feet(myHouse)**</p>\n",
    "\n",
    "### Problems\n",
    "\n",
    "Are we sure that the best model for our problem is linear? It could also be **quadratic** or more.\n",
    "\n",
    "## High order regression\n",
    "It is a sub-type of linear regression (actually everybody refers to it as linear regression).\n",
    "\n",
    "If we take into account the quadratic regression the model is no more an equation that defines a straight line but it is a **parabola**:\n",
    "<p style='text-align:center'>**fW(x) = W0 + W1*x + W2*x^2**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"VUOF44KIMPF68XS35D6DD8F5JD40WTTQ.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same formula of the RSS calculation, substituting the parabola equation in the distance calculus, we can verify if this model is better or worse than the linear one.\n",
    "\n",
    "We can increase the order of the function used to build the model but it can produce wrong results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"HXTXUDL8V42ELFJYSRKCDLXVJUBDO8OI.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the RSS value is the minimum possible one **BUT** the model is wrong: the value of my house predicted by this model is **TOO LOW**!!\n",
    "\n",
    "This problem is called <span style='color:red'>OVERFITTING</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we choose the proper model?\n",
    "The key idea is that we want to simulate predictions on observations that we already have.\n",
    "\n",
    "First of all, we have to split our dataset into two categories;\n",
    "- **Training set** : Data used to fit our model (blue dots).\n",
    "- **Test set** : Data use in order to validate our predictions (gray dots).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"I6H3C7RFDXDTCB0R87TMLI2AGYI68J2G.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to calculate the **training error** thai is the RSS **only** of the data in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"Y6QHFXXLWJOC5WX9VEQOBT7DDLL74P20.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same calculus in order to retrieve the **test error** (The RSS calculated only on the data included in the test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"XWMIWSBX54TSNG1PXU4V0K9BE14QEJYJ.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training / Test curves\n",
    "As we saw before, the higher the polynomial that builds our model is the lower will be our training error (the RSS calculated only on the training set). This happens because the line can touch perfectly every single data of our model, but this is not an indication of correctness (Remember the **OVERFITTING** problem!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"FNJUXODVTK27HJL2FMST6O19LS9QY4XK.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the test error things are different: the error decrease until a certain model complexity but after that point the error will increase, detecting the overfitting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"PRHGV4QP8RNX6SW8UL1O4CIENH0ISPY3.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding other features\n",
    "In this example, the square feet feature of the house is not sufficient in order to make a good prediction. We can have an house that has the same square feet as ours but only one bathroom instead of three.\n",
    "\n",
    "We can add other feature increasing the dimensions of our graph (for example adding the number of bathrooms on the z-axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"QPQODESA9FKX5GV0LJ3V8E5696PS9SRS.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our model won't be a line anymore but a **plane** identified by this equation:\n",
    "<p style='text-align:center'>**fW(x) = W0 + W1*square_feet + W2*#bathrooms**</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"I6NL8B94HEM5L5Q4LJKMRS740Q82JIVO.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression pipeline summary\n",
    "We can summarize the whole process of regression described so far with this picture: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"N0I182O9KRI64CLGFC7JM704SBSGXLLN.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start from a training data with a lot of features.\n",
    "2. With the feature extraction component select only the important features.\n",
    "3. With a machine learning model, regression in this case, predict the values we want.\n",
    "4. Validate the predictions with the test set in the quality metric component.\n",
    "5. With a machine learning algorithm adjust the parameters of the model with respect to the results of the quality metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "**Classification** : classification is the problem of identifying to which of a set of categories a new observation belongs, on the basis of a training set of data containing observations whose category membership is known.\n",
    "\n",
    "##Â Use case - Intelligent restaurant classifier\n",
    "\n",
    "1. Get all the reviews about one restaurant\n",
    "2. Break all reviews into sentence\n",
    "3. Select only the sentences regarding the topic in which we are interested (sushi for example)\n",
    "4. Pass these sentences as input into a **sentence sentiment classifier** in order to extract if a sentence is positive or negative.\n",
    "5. Create the prediction about the quality of the topic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear classifier\n",
    "\n",
    "A simple linear classifier takes as input:\n",
    "* The sentence that has to be classified\n",
    "* A list of words with their weights (positive words weight > 0; negative words weight < 0)\n",
    "\n",
    "The classifier then sums up the weight of each word inside the sentence and it classifies the sentence as follow:\n",
    "* **result > 0 --> positive sentence**\n",
    "* **result < 0 --> negative sentence**\n",
    "\n",
    "This type of classifier is called **linear** because **outputs are weighted sum of inputs**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"XFYYSPNO0W9QWH5MY6CBPT3V8I1407L4.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems\n",
    "\n",
    "* How do we get the list of positive and negative words?\n",
    "\n",
    "\n",
    "* Words have different degree of sentiment (**awesome** is more positive than **good**)\n",
    "\n",
    "These two problems are addressed by **learning classifier**\n",
    "\n",
    "* Single words are not enough (**good** is positive but **not good** is negative)\n",
    "\n",
    "This problem instead is addressed by **elaborate features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision boundaries\n",
    "We need to find a threshold that differentiates the positive sentence from the negative ones.\n",
    "\n",
    "This threshold is called **decision boundary**\n",
    "\n",
    "If we consider only two words, awful and awesome for example, weighed respectively -1.5 and 1.0 the decision boundary is retrieved in this way:\n",
    "\n",
    "<p style='text-align:center'>**1.0#awesome -1.5#awful = 0**</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"HLCK21LOA6YWXJG902ECUOE4PK3W2LBR.png\"/>\n",
    "\n",
    "In this case the decision boundary is represented by a line (we have only two words so only two dimensions).\n",
    "If we have had:\n",
    "\n",
    "* 3 words --> plane\n",
    "\n",
    "* more than 3 words --> hyperplane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier (learning the weights)\n",
    "In order to train a classifier we have to:\n",
    "1. Get a dataset of sentences already marked as positive or negative\n",
    "2. Split the dataset into a training set and a test set\n",
    "3. feed the training set as input to the **learn classifier** (this learn classifier is gonna learn the appropriate weights for the words)\n",
    "4. The weights learned by the learn classifier are used to score every element in the test set and evaluate how good is our learn classifier \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"UR5IRR9MPVS4MOHS37UJDYQYG21EKS55.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the evaluation of the weights\n",
    "In order to test the goodness of the retrieved weights we need to:\n",
    "1. Feed a number of sentences, already known to be positive or negative, to our classifier \n",
    "2. Get the prediction made by our classifier\n",
    "3. Compare the prediction with the real sentiment of the sentence\n",
    "4. If the prediction matches the real sentiment than correct++ otherwise mistakes++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"BKP2NX0BEFL537QSDB853NE55TXB48OC.png\"/>\n",
    "\n",
    "The **error rate of the classifier** is then calculated as:\n",
    "<p style='text-align:center'>**classifier_error = #mistakes / #sentences**</p>\n",
    "\n",
    "while the **accuracy of the classifier** is retrieved as:\n",
    "<p style='text-align:center'>**classifier_accuracy = #correct / #sentences**</p>\n",
    "\n",
    "obviously the error and the accuracy are bound together:\n",
    "<p style='text-align:center'>**classifier_error = 1 - classifier_accuracy**</p>\n",
    "\n",
    "### What is a good accuracy?\n",
    "At **least** our accuracy must be better than the random guesses on data (for example if I have only two classes of decision like positive and negative, my accuracy must be > 50%).\n",
    "\n",
    "Given that a high accuracy rate isn't always a good indicator of the quality of our classifier. For example if we consider the SPAM email example the data shows that 90% of the emails sent are SPAM; if we have a classifier with a 90% accuracy predicting every email sent is SPAM gives us a 90% of accuracy but actually **our classifier always make the SAME prediction for every email!!!**.\n",
    "\n",
    "This problem is called <span style='color:red'>MAJORITY CLASS PREDICTION</span>.\n",
    "\n",
    "This problem causes the **impression that our classifier has amazing performance when there is class imbalance (one class is more common than others)** even if it was poorly designed.\n",
    "\n",
    "\n",
    "So how can we design a good classifier? we have to ask ourself the following questions:\n",
    "* Is there class imbalance?\n",
    "\n",
    "\n",
    "* How does it compare to random guessing?\n",
    "\n",
    "\n",
    "* What accuracy does my application need?\n",
    "\n",
    "### Types of errors\n",
    "The types of error are given by the relationship between the **predicted labels** and the **true labels**. Actually we can have:\n",
    "* **False positives --> True label negative - predicted label positive**\n",
    "\n",
    "* **False negatives --> True label positive - predicted label negative**\n",
    "\n",
    "The relationship between the labels are summarized by the **confusion matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"A5BCMUQER2MIY183E4UTYLPODW841E4F.png\"/>\n",
    "\n",
    "This matrix can give us some clues about our prediction model and how to improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example we can see that a person that has cold can be confused both as a healthy person or one who has a Flu so it could be better to improve our model to better classifies these patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curves\n",
    "A learning curve relates the amount of data that we have for training set with the error that we are making.\n",
    "\n",
    "The more data we have the better the model will be **as long as the QUALITY of data is high**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"FPURUS44J8RAWL4TDGQFM7LI3BTWJWKY.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the example increasing the amount of data for the training set will decrease the test error, but this error can not decrease forever: there will be always a gap from the error and 0. This gap is called **BIAS**.\n",
    "\n",
    "In order to decrease the bias we have to increase the complexity of our model, for example for a sentiment analysis model consider bigrams instead of single words can decrease the bias, but the amount of data needed for the training set increase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"TB3ITO3SG73P3J2R6ADG2MM065IABJ2J.png\"/>\n",
    "\n",
    "## Level of confidence\n",
    "Usually a classifier does not return only the predicted label but it returns also the **confidence level** related to that prediction.\n",
    "\n",
    "The confidence level is given by the following conditional probability:\n",
    "\n",
    "<p style='text-align:center'>**confidence_level = P(predicted_label | input_sentence)**</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification pipeline summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"HRNN8T2HWP2S0M5UOL5FIJG90NLG62DR.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start from a training data that has reviews and their sentiments\n",
    "2. With the feature extraction component extract the word counts.\n",
    "3. With a machine learning model, classification in this case, predict the sentiment related to the input review .\n",
    "4. Feed the prediction made to the quality metric component and compare it with the real sentiment related to that review.\n",
    "5. With a machine learning algorithm adjust the weight for each word in order to improve classification accuracy.\n",
    "\n",
    "# Clustering and similarity\n",
    "\n",
    "**Clustering and similarity** : we have a lot of observations and we want to infer some kind of structure underlying these observations.\n",
    "\n",
    "Groups of related observation are called **clusters**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": false,
   "toc_section_display": "none",
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "toc_position": {
   "height": "546px",
   "left": "965.125px",
   "right": "20px",
   "top": "119px",
   "width": "292px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
